# üîß Troubleshooting Guide

## üìã M·ª•c L·ª•c

1. [Common Issues](#common-issues)
2. [Provider-Specific Issues](#provider-specific-issues)
3. [Performance Issues](#performance-issues)
4. [Output Quality Issues](#output-quality-issues)
5. [Development Issues](#development-issues)

---

## üêõ COMMON ISSUES

### Issue 1: "Proxy server kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c"

**Symptoms**:
- Error: "Failed to fetch"
- Toast notification: "L·ªói k·∫øt n·ªëi AI"
- Console: "Network error"

**Solutions**:

‚úÖ **Step 1**: Ki·ªÉm tra proxy server ƒëang ch·∫°y
```bash
# Check if port 3001 is active
netstat -ano | findstr :3001

# ho·∫∑c
Get-Process -Id (Get-NetTCPConnection -LocalPort 3001).OwningProcess
```

‚úÖ **Step 2**: Start proxy server
```bash
# T·ª´ project root
python proxy-server-python.py

# ho·∫∑c
.\start-python-server.bat
```

‚úÖ **Step 3**: Verify server ƒëang ch·∫°y
```bash
# Test health endpoint
curl http://localhost:3001/health

# Test all providers
curl http://localhost:3001/api/test-all
```

‚úÖ **Step 4**: Check firewall
- Windows Firewall c√≥ th·ªÉ block port 3001
- Th√™m exception cho Python/Node.js

---

### Issue 2: "Prompt generation failed - T·∫•t c·∫£ providers ƒë·ªÅu l·ªói"

**Symptoms**:
- Output: "All providers failed"
- Fallback to demo mode
- Toast: "ƒêang s·ª≠ d·ª•ng ch·∫ø ƒë·ªô demo"

**Solutions**:

‚úÖ **Step 1**: Test t·ª´ng provider ri√™ng l·∫ª
```bash
# Test OpenRouter
curl http://localhost:3001/api/test-openrouter

# Test Groq
curl http://localhost:3001/api/test-groq

# Test Gemini
curl http://localhost:3001/api/test-gemini
```

‚úÖ **Step 2**: Ki·ªÉm tra API keys
```python
# Trong proxy-server-python.py
# Verify keys kh√¥ng r·ªóng
OPENROUTER_API_KEY = 'sk-or-v1-...'  # Should not be empty
GROQ_API_KEY = 'gsk_...'
GEMINI_API_KEY = 'AIzaSy...'
```

‚úÖ **Step 3**: Check rate limits
- OpenRouter: Xem usage dashboard
- Groq: Check free tier limits
- Gemini: 15 requests/minute limit

‚úÖ **Step 4**: Try different model
```javascript
// Trong UI, ch·ªçn model kh√°c
// ho·∫∑c trong code:
CONFIG.CURRENT_MODEL = 'llama-3.1-8b-instant'; // Groq model
```

---

### Issue 3: "Output qu√° ng·∫Øn ho·∫∑c qu√° d√†i"

**Symptoms**:
- Output ch·ªâ 100-150 t·ª´ (qu√° ng·∫Øn)
- ho·∫∑c Output >1000 t·ª´ b·ªã cut off

**Solutions**:

‚úÖ **Qu√° ng·∫Øn - C·∫£i thi·ªán input**:
```javascript
// Bad input:
"T·∫°o website"

// Good input:
"T·∫°o full-stack e-commerce website v·ªõi:
- React frontend
- Node.js backend
- PostgreSQL database
- Payment integration
- Admin dashboard
Include: architecture, code structure, deployment guide"
```

‚úÖ **Qu√° d√†i - Adjust max_tokens**:
```javascript
// Trong script.js, line ~104
MAX_TOKENS: 3000  // TƒÉng t·ª´ 2000 l√™n 3000
```

‚úÖ **Set constraints trong input**:
```
"[Your request]

Requirements:
- Keep output between 400-600 words
- Focus on key requirements only
- Provide concise but complete information"
```

---

### Issue 4: "Output kh√¥ng nh·∫•t qu√°n gi·ªØa c√°c l·∫ßn generate"

**Symptoms**:
- C√πng input nh∆∞ng output kh√°c nhau m·ªói l·∫ßn
- Quality fluctuates (l√∫c t·ªët l√∫c x·∫•u)

**Solutions**:

‚úÖ **Gi·∫£m temperature**:
```javascript
// Trong script.js, line ~104
TEMPERATURE: 0.5  // Gi·∫£m t·ª´ 0.7 xu·ªëng 0.5
// Lower = more consistent, higher = more creative
```

‚úÖ **S·ª≠ d·ª•ng enhanced prompt** (ƒë√£ implement!):
- Enhanced prompt c√≥ examples ‚Üí consistent h∆°n
- Clear structure ‚Üí predictable outputs

‚úÖ **Ch·ªçn model deterministic**:
```javascript
// DeepSeek Chat V3.1 - more consistent
CONFIG.CURRENT_MODEL = 'deepseek-chat-v3.1';

// vs Mixtral - more creative/varied
```

---

## üîå PROVIDER-SPECIFIC ISSUES

### OpenRouter Issues

#### "402 Payment Required"

**Cause**: ƒêang d√πng paid model nh∆∞ng API key kh√¥ng c√≥ credits

**Solution**:
```javascript
// Switch to FREE models only
const FREE_MODELS = [
    'deepseek-chat-v3.1',  // 5‚≠ê
    'qwen3-coder-free',    // 5‚≠ê
    'llama-3.3-70b',       // 5‚≠ê
    'grok-4-fast'          // 5‚≠ê
];

// Avoid paid models
const PAID_MODELS = [
    'gpt-4o',              // ‚ùå Paid
    'claude-3-opus',       // ‚ùå Paid
    'gpt-4-turbo'          // ‚ùå Paid
];
```

#### "429 Rate Limit Exceeded"

**Cause**: Qu√° nhi·ªÅu requests t·ªõi c√πng model

**Solution**:
‚úÖ **Automatic fallback** (ƒë√£ c√≥):
- System t·ª± ƒë·ªông th·ª≠ c√°c fallback models
- Xem console logs ƒë·ªÉ bi·∫øt model n√†o ƒë∆∞·ª£c d√πng

‚úÖ **Manual retry v·ªõi model kh√°c**:
```javascript
// Try different 5-star model
'deepseek-chat-v3.1' ‚Üí 'llama-3.3-70b' ‚Üí 'qwen3-14b'
```

‚úÖ **Wait v√† retry**:
```bash
# Wait 1-2 minutes
sleep 120

# Then try again
```

---

### Groq Issues

#### "Too many requests"

**Cause**: Free tier rate limit (r·∫•t generous nh∆∞ng c√≥ limit)

**Solution**:
‚úÖ Switch to other provider:
```javascript
// Groq ‚Üí OpenRouter
CONFIG.CURRENT_PROVIDER = 'openrouter';

// ho·∫∑c Groq ‚Üí Gemini
CONFIG.CURRENT_PROVIDER = 'gemini';
```

#### "Model not found"

**Cause**: Sai model name

**Valid Groq Models**:
```javascript
'llama-3.1-8b-instant'     // ‚úÖ Correct
'llama-3.1-70b-versatile'  // ‚úÖ Correct
'mixtral-8x7b-32768'       // ‚úÖ Correct

'llama-3.1-8b'             // ‚ùå Wrong (missing -instant)
'llama3-8b'                // ‚ùå Wrong (wrong format)
```

---

### Gemini Issues

#### "Quota exceeded for quota metric 'GenerateContent request'"

**Cause**: V∆∞·ª£t 15 requests/minute

**Solution**:
‚úÖ **Wait 1 minute**:
```javascript
// Auto fallback s·∫Ω switch sang provider kh√°c
// ho·∫∑c manual wait:
setTimeout(() => retryGeneration(), 60000); // Wait 1 min
```

‚úÖ **Use OpenRouter/Groq first**:
```javascript
// Set OpenRouter as default
CONFIG.DEFAULT_PROVIDER = 'openrouter';
```

#### "API key not valid"

**Check API key format**:
```javascript
// Valid format
'AIzaSyDAnBQKPWkJigLq_Hiy4PmqPvLkdW2AQAo'

// Should start with 'AIzaSy'
```

---

## ‚ö° PERFORMANCE ISSUES

### Issue: "Response time qu√° ch·∫≠m (>10 seconds)"

**Diagnosis**:
```javascript
// Measure actual response time
console.time('API Call');
await callAIAPI(input, template);
console.timeEnd('API Call');
```

**Solutions by Provider**:

| Provider | Expected Time | If Slower |
|----------|---------------|-----------|
| Groq | 0.5-2s | Switch model ho·∫∑c provider |
| Gemini | 1-3s | Rate limited? Wait |
| OpenRouter | 2-5s | Normal, pick faster model |

‚úÖ **Switch to faster model**:
```javascript
// FASTEST
'llama-3.1-8b-instant' (Groq) // 0.5-1s

// FAST
'gemini-2.0-flash-exp' (Gemini) // 1-2s
'grok-4-fast' (OpenRouter) // 1-2s

// BALANCED (Quality vs Speed)
'deepseek-chat-v3.1' (OpenRouter) // 2-4s
```

‚úÖ **Reduce max_tokens**:
```javascript
MAX_TOKENS: 1500  // Gi·∫£m t·ª´ 2000 ‚Üí faster response
```

---

### Issue: "UI b·ªã lag khi typing"

**Cause**: Kh√¥ng c√≥ debounce

**Check if debounce ho·∫°t ƒë·ªông**:
```javascript
// Trong script.js, search for "handleInputChange"
// N√™n c√≥ debounce logic
```

**Solution**: ƒê√£ c√≥ trong code, nh∆∞ng c√≥ th·ªÉ tƒÉng delay:
```javascript
const DEBOUNCE_DELAY = 500; // ms

let debounceTimer;
function handleInputChange() {
    clearTimeout(debounceTimer);
    debounceTimer = setTimeout(() => {
        // Actual handler
    }, DEBOUNCE_DELAY);
}
```

---

## üìä OUTPUT QUALITY ISSUES

### Issue: "Output kh√¥ng ƒë·ªß chi ti·∫øt"

**Diagnosis**:
```javascript
// Check word count
const wordCount = output.split(' ').length;
console.log('Word count:', wordCount);
// Should be 300-600 words
```

**Solutions**:

‚úÖ **Improve input specificity** (quan tr·ªçng nh·∫•t!):
```
Bad: "T·∫°o app"
Good: "T·∫°o mobile app v·ªõi features X, Y, Z. Tech stack: A, B, C. Requirements: ..."
```

‚úÖ **Use better model**:
```javascript
// For detailed outputs
'deepseek-chat-v3.1'  // 5‚≠ê Best chat
'llama-3.3-70b'       // 5‚≠ê Excellent chat
'qwen3-coder-free'    // 5‚≠ê Best coding (detailed)

// Avoid lightweight models for complex tasks
'llama-3.2-3b'        // 3‚≠ê Too small for complex prompts
```

‚úÖ **Check enhanced prompt active**:
```javascript
// Verify systemPrompt trong PROMPT_TEMPLATES.universal
// Should be ~200 lines (enhanced), not 1 line (old)
console.log(PROMPT_TEMPLATES.universal.systemPrompt.length);
// Should be ~2000+ characters
```

---

### Issue: "Output b·ªã l·∫∑p ho·∫∑c repetitive"

**Cause**: Model hallucination ho·∫∑c temperature qu√° cao

**Solutions**:

‚úÖ **Reduce temperature**:
```javascript
TEMPERATURE: 0.5  // Gi·∫£m t·ª´ 0.7
```

‚úÖ **Add no-repeat instruction**:
```javascript
userInput += "\n\nIMPORTANT: Avoid repetition. Each section should have unique, non-redundant content."
```

‚úÖ **Try different model**:
```javascript
// Some models handle repetition better
'deepseek-chat-v3.1'  // Good at avoiding repetition
'qwen3-14b'           // Well balanced
```

---

## üíª DEVELOPMENT ISSUES

### Issue: "Cannot run proxy server - Python error"

**Error**: `ModuleNotFoundError: No module named 'flask'`

**Solution**:
```bash
# Install dependencies
pip install flask flask-cors requests

# ho·∫∑c
pip install -r requirements.txt

# Verify installation
pip list | findstr flask
```

**Error**: `Python was not found`

**Solution**:
```bash
# Install Python 3.8+
# Download: https://www.python.org/downloads/

# Add to PATH
setx PATH "%PATH%;C:\Python312"

# Verify
python --version
```

---

### Issue: "Port 3001 already in use"

**Error**: `Address already in use: 3001`

**Solution**:

‚úÖ **Find v√† kill process**:
```powershell
# Find PID on port 3001
Get-Process -Id (Get-NetTCPConnection -LocalPort 3001).OwningProcess

# Kill process
Stop-Process -Id <PID> -Force
```

‚úÖ **Use different port**:
```python
# Trong proxy-server-python.py
PORT = 3002  # Change from 3001

# Update trong script.js
PROXY_SERVER_URL: 'http://localhost:3002'
```

---

### Issue: "CORS errors in browser console"

**Error**: 
```
Access to fetch at 'http://localhost:3001/api/...' from origin 'http://localhost:8000' has been blocked by CORS policy
```

**Solution**:

‚úÖ **Verify CORS enabled trong proxy**:
```python
# proxy-server-python.py
from flask_cors import CORS
app = Flask(__name__)
CORS(app)  # Should be present
```

‚úÖ **Check browser loading from correct origin**:
```javascript
// Should be localhost:8000 ho·∫∑c localhost:3001
console.log(window.location.origin);
```

---

## üß™ TESTING & DEBUGGING

### Debug Mode

```javascript
// Enable debug logging
APP_STATE.debug = true;

// Check provider status
console.log('Current Provider:', CONFIG.CURRENT_PROVIDER);
console.log('Current Model:', CONFIG.CURRENT_MODEL);

// Test API directly
await testAIConnection('openrouter');
await testAIConnection('groq');
await testAIConnection('gemini');
```

### Verbose Logging

```javascript
// Add trong callAIAPI function
console.log('üì§ Request:', {
    provider: CONFIG.CURRENT_PROVIDER,
    model: CONFIG.CURRENT_MODEL,
    inputLength: userInput.length
});

console.log('üì• Response:', {
    success: data.success,
    outputLength: output.length,
    usage: data.usage
});
```

### Test Endpoints Manually

```bash
# Test server health
curl http://localhost:3001/health

# Test provider connections
curl http://localhost:3001/api/test-all

# Test actual generation
curl -X POST http://localhost:3001/api/openrouter/chat \
  -H "Content-Type: application/json" \
  -d '{"systemPrompt":"Test","userInput":"Hello","model":"deepseek-chat-v3.1"}'
```

---

## üìû STILL NEED HELP?

### Step 1: Check Logs
- Browser Console (F12)
- Proxy Server Terminal
- Network tab trong DevTools

### Step 2: Collect Information
```
- OS: Windows/Mac/Linux
- Browser: Chrome/Firefox/Safari version X
- Provider: OpenRouter/Groq/Gemini
- Model: [model name]
- Error message: [exact error]
- Steps to reproduce: [1, 2, 3...]
```

### Step 3: Create GitHub Issue
```markdown
**Title**: [Brief description]

**Environment**:
- OS: Windows 10
- Browser: Chrome 120
- Version: 2.0.0

**Description**:
[What happened]

**Expected**:
[What should happen]

**Steps to Reproduce**:
1. ...
2. ...

**Logs**:
```
[Paste console errors]
```

**Screenshots**: [If applicable]
```

---

## ‚úÖ PREVENTION CHECKLIST

ƒê·ªÉ tr√°nh issues:

- [ ] Lu√¥n start proxy server tr∆∞·ªõc khi use app
- [ ] Test `/api/test-all` ƒë·ªãnh k·ª≥
- [ ] Monitor rate limits (don't spam)
- [ ] Use appropriate models (free vs paid)
- [ ] Write detailed inputs (better outputs)
- [ ] Check console logs for errors
- [ ] Keep dependencies updated
- [ ] Backup working configurations

---

**Last Updated**: October 1, 2025  
**Version**: 2.0.0  
**Maintained by**: AI Prompt Assistant Team

